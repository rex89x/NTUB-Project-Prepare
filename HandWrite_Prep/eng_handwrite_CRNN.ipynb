{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"eng_handwrite_CRNN.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyODIELbW/5x4VHGElrLw18f"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"jrgLAYNnIpga"},"source":["#https://www.kaggle.com/samfc10/handwriting-recognition-using-crnn-in-keras\n","import os\n","import cv2\n","import random\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","import tensorflow as tf\n","from keras import backend as K\n","from keras.models import Model\n","from keras.layers import Input, Conv2D, MaxPooling2D, Reshape, Bidirectional, LSTM, Dense, Lambda, Activation, BatchNormalization, Dropout\n","from keras.optimizers import Adam"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z4ZUrRvQJOw9"},"source":["train = pd.read_csv('/kaggle/input/handwriting-recognition/written_name_train_v2.csv')\n","valid = pd.read_csv('/kaggle/input/handwriting-recognition/written_name_validation_v2.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yMV5y3U7JQLE"},"source":["plt.figure(figsize=(15, 10))\n","\n","for i in range(6):\n","    ax = plt.subplot(2, 3, i+1)\n","    img_dir = '/kaggle/input/handwriting-recognition/train_v2/train/'+train.loc[i, 'FILENAME']\n","    image = cv2.imread(img_dir, cv2.IMREAD_GRAYSCALE)\n","    plt.imshow(image, cmap = 'gray')\n","    plt.title(train.loc[i, 'IDENTITY'], fontsize=12)\n","    plt.axis('off')\n","\n","plt.subplots_adjust(wspace=0.2, hspace=-0.8)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"19c6nYyvJRbI"},"source":["print(\"Number of NaNs in train set      : \", train['IDENTITY'].isnull().sum())\n","print(\"Number of NaNs in validation set : \", valid['IDENTITY'].isnull().sum())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"p_zybzXVJSuw"},"source":["train.dropna(axis=0, inplace=True)\n","valid.dropna(axis=0, inplace=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0cuTfTNzJTzd"},"source":["unreadable = train[train['IDENTITY'] == 'UNREADABLE']\n","unreadable.reset_index(inplace = True, drop=True)\n","\n","plt.figure(figsize=(15, 10))\n","\n","for i in range(6):\n","    ax = plt.subplot(2, 3, i+1)\n","    img_dir = '/kaggle/input/handwriting-recognition/train_v2/train/'+unreadable.loc[i, 'FILENAME']\n","    image = cv2.imread(img_dir, cv2.IMREAD_GRAYSCALE)\n","    plt.imshow(image, cmap = 'gray')\n","    plt.title(unreadable.loc[i, 'IDENTITY'], fontsize=12)\n","    plt.axis('off')\n","\n","plt.subplots_adjust(wspace=0.2, hspace=-0.8)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3uqUjdFZJVPA"},"source":["train = train[train['IDENTITY'] != 'UNREADABLE']\n","valid = valid[valid['IDENTITY'] != 'UNREADABLE']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oGpO1yPaJWkP"},"source":["train['IDENTITY'] = train['IDENTITY'].str.upper()\n","valid['IDENTITY'] = valid['IDENTITY'].str.upper()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"k9ny536BJX-I"},"source":["train.reset_index(inplace = True, drop=True) \n","valid.reset_index(inplace = True, drop=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"caH8f6nOJZFQ"},"source":["def preprocess(img):\n","    (h, w) = img.shape\n","    \n","    final_img = np.ones([64, 256])*255 # blank white image\n","    \n","    # crop\n","    if w > 256:\n","        img = img[:, :256]\n","        \n","    if h > 64:\n","        img = img[:64, :]\n","    \n","    \n","    final_img[:h, :w] = img\n","    return cv2.rotate(final_img, cv2.ROTATE_90_CLOCKWISE)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4L5_3hJLJabw"},"source":["train_size = 30000\n","valid_size= 3000"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"N68lyDDCJb7M"},"source":["train_x = []\n","\n","for i in range(train_size):\n","    img_dir = '/kaggle/input/handwriting-recognition/train_v2/train/'+train.loc[i, 'FILENAME']\n","    image = cv2.imread(img_dir, cv2.IMREAD_GRAYSCALE)\n","    image = preprocess(image)\n","    image = image/255.\n","    train_x.append(image)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wamtt6_hJdRY"},"source":["valid_x = []\n","\n","for i in range(valid_size):\n","    img_dir = '/kaggle/input/handwriting-recognition/validation_v2/validation/'+valid.loc[i, 'FILENAME']\n","    image = cv2.imread(img_dir, cv2.IMREAD_GRAYSCALE)\n","    image = preprocess(image)\n","    image = image/255.\n","    valid_x.append(image)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xdDrD6URJehA"},"source":["train_x = np.array(train_x).reshape(-1, 256, 64, 1)\n","valid_x = np.array(valid_x).reshape(-1, 256, 64, 1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WRKmbHh3JfuB"},"source":["alphabets = u\"ABCDEFGHIJKLMNOPQRSTUVWXYZ-' \"\n","max_str_len = 24 # max length of input labels\n","num_of_characters = len(alphabets) + 1 # +1 for ctc pseudo blank\n","num_of_timestamps = 64 # max length of predicted labels\n","\n","\n","def label_to_num(label):\n","    label_num = []\n","    for ch in label:\n","        label_num.append(alphabets.find(ch))\n","        \n","    return np.array(label_num)\n","\n","def num_to_label(num):\n","    ret = \"\"\n","    for ch in num:\n","        if ch == -1:  # CTC Blank\n","            break\n","        else:\n","            ret+=alphabets[ch]\n","    return ret"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yjq9MUG_JhG6"},"source":["name = 'JEBASTIN'\n","print(name, '\\n',label_to_num(name))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XfMCzs1QJiNZ"},"source":["train_y = np.ones([train_size, max_str_len]) * -1\n","train_label_len = np.zeros([train_size, 1])\n","train_input_len = np.ones([train_size, 1]) * (num_of_timestamps-2)\n","train_output = np.zeros([train_size])\n","\n","for i in range(train_size):\n","    train_label_len[i] = len(train.loc[i, 'IDENTITY'])\n","    train_y[i, 0:len(train.loc[i, 'IDENTITY'])]= label_to_num(train.loc[i, 'IDENTITY'])  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cLFH3iwVJj0H"},"source":["valid_y = np.ones([valid_size, max_str_len]) * -1\n","valid_label_len = np.zeros([valid_size, 1])\n","valid_input_len = np.ones([valid_size, 1]) * (num_of_timestamps-2)\n","valid_output = np.zeros([valid_size])\n","\n","for i in range(valid_size):\n","    valid_label_len[i] = len(valid.loc[i, 'IDENTITY'])\n","    valid_y[i, 0:len(valid.loc[i, 'IDENTITY'])]= label_to_num(valid.loc[i, 'IDENTITY'])    \n","print('True label : ',train.loc[100, 'IDENTITY'] , '\\ntrain_y : ',train_y[100],'\\ntrain_label_len : ',train_label_len[100], \n","      '\\ntrain_input_len : ', train_input_len[100])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jm6jEmTkJlbw"},"source":["input_data = Input(shape=(256, 64, 1), name='input')\n","\n","inner = Conv2D(32, (3, 3), padding='same', name='conv1', kernel_initializer='he_normal')(input_data)  \n","inner = BatchNormalization()(inner)\n","inner = Activation('relu')(inner)\n","inner = MaxPooling2D(pool_size=(2, 2), name='max1')(inner)\n","\n","inner = Conv2D(64, (3, 3), padding='same', name='conv2', kernel_initializer='he_normal')(inner)\n","inner = BatchNormalization()(inner)\n","inner = Activation('relu')(inner)\n","inner = MaxPooling2D(pool_size=(2, 2), name='max2')(inner)\n","inner = Dropout(0.3)(inner)\n","\n","inner = Conv2D(128, (3, 3), padding='same', name='conv3', kernel_initializer='he_normal')(inner)\n","inner = BatchNormalization()(inner)\n","inner = Activation('relu')(inner)\n","inner = MaxPooling2D(pool_size=(1, 2), name='max3')(inner)\n","inner = Dropout(0.3)(inner)\n","\n","# CNN to RNN\n","inner = Reshape(target_shape=((64, 1024)), name='reshape')(inner)\n","inner = Dense(64, activation='relu', kernel_initializer='he_normal', name='dense1')(inner)\n","\n","## RNN\n","inner = Bidirectional(LSTM(256, return_sequences=True), name = 'lstm1')(inner)\n","inner = Bidirectional(LSTM(256, return_sequences=True), name = 'lstm2')(inner)\n","\n","## OUTPUT\n","inner = Dense(num_of_characters, kernel_initializer='he_normal',name='dense2')(inner)\n","y_pred = Activation('softmax', name='softmax')(inner)\n","\n","model = Model(inputs=input_data, outputs=y_pred)\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"K_lx806RJm4c"},"source":["# the ctc loss function\n","def ctc_lambda_func(args):\n","    y_pred, labels, input_length, label_length = args\n","    # the 2 is critical here since the first couple outputs of the RNN\n","    # tend to be garbage\n","    y_pred = y_pred[:, 2:, :]\n","    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LdAFYzHJJoTh"},"source":["labels = Input(name='gtruth_labels', shape=[max_str_len], dtype='float32')\n","input_length = Input(name='input_length', shape=[1], dtype='int64')\n","label_length = Input(name='label_length', shape=[1], dtype='int64')\n","\n","ctc_loss = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([y_pred, labels, input_length, label_length])\n","model_final = Model(inputs=[input_data, labels, input_length, label_length], outputs=ctc_loss)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UZ7852zdJppC"},"source":["# the loss calculation occurs elsewhere, so we use a dummy lambda function for the loss\n","model_final.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=Adam(lr = 0.0001))\n","\n","model_final.fit(x=[train_x, train_y, train_input_len, train_label_len], y=train_output, \n","                validation_data=([valid_x, valid_y, valid_input_len, valid_label_len], valid_output),\n","                epochs=60, batch_size=128)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bpkcd1E8Jqxr"},"source":["preds = model.predict(valid_x)\n","decoded = K.get_value(K.ctc_decode(preds, input_length=np.ones(preds.shape[0])*preds.shape[1], \n","                                   greedy=True)[0][0])\n","\n","prediction = []\n","for i in range(valid_size):\n","    prediction.append(num_to_label(decoded[i]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EpzdB_osJswA"},"source":["y_true = valid.loc[0:valid_size, 'IDENTITY']\n","correct_char = 0\n","total_char = 0\n","correct = 0\n","\n","for i in range(valid_size):\n","    pr = prediction[i]\n","    tr = y_true[i]\n","    total_char += len(tr)\n","    \n","    for j in range(min(len(tr), len(pr))):\n","        if tr[j] == pr[j]:\n","            correct_char += 1\n","            \n","    if pr == tr :\n","        correct += 1 \n","    \n","print('Correct characters predicted : %.2f%%' %(correct_char*100/total_char))\n","print('Correct words predicted      : %.2f%%' %(correct*100/valid_size))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JHlCmW7ZJuKG"},"source":["test = pd.read_csv('/kaggle/input/handwriting-recognition/written_name_test_v2.csv')\n","\n","plt.figure(figsize=(15, 10))\n","for i in range(6):\n","    ax = plt.subplot(2, 3, i+1)\n","    img_dir = '/kaggle/input/handwriting-recognition/test_v2/test/'+test.loc[i, 'FILENAME']\n","    image = cv2.imread(img_dir, cv2.IMREAD_GRAYSCALE)\n","    plt.imshow(image, cmap='gray')\n","    \n","    image = preprocess(image)\n","    image = image/255.\n","    pred = model.predict(image.reshape(1, 256, 64, 1))\n","    decoded = K.get_value(K.ctc_decode(pred, input_length=np.ones(pred.shape[0])*pred.shape[1], \n","                                       greedy=True)[0][0])\n","    plt.title(num_to_label(decoded[0]), fontsize=12)\n","    plt.axis('off')\n","    \n","plt.subplots_adjust(wspace=0.2, hspace=-0.8)"],"execution_count":null,"outputs":[]}]}